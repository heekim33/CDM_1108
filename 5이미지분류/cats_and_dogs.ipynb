{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "import tensorflow.keras\n",
    "tensorflow.keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소규모 데이터셋을 저장할 디렉터리\n",
    "base_dir = './datasets/small'\n",
    "\n",
    "# 훈련, 검증, 테스트 분할을 위한 디렉터리\n",
    "train_dir = './datasets/small/train'\n",
    "validation_dir = './datasets/small/validation'\n",
    "test_dir = './datasets/small/test'\n",
    "\n",
    "\n",
    "# 훈련용 고양이 사진 디렉터리\n",
    "train_cats_dir = './datasets/small/train/cats'\n",
    "\n",
    "# 훈련용 강아지 사진 디렉터리\n",
    "train_dogs_dir = './datasets/small/train/dogs'\n",
    "\n",
    "# 검증용 고양이 사진 디렉터리\n",
    "validation_cats_dir = './datasets/small/validation/cats'\n",
    "\n",
    "# 검증용 강아지 사진 디렉터리\n",
    "validation_dogs_dir = './datasets/small/validation/dogs'\n",
    "\n",
    "# 테스트용 고양이 사진 디렉터리\n",
    "test_cats_dir = './datasets/small/test/cats'\n",
    "\n",
    "# 테스트용 강아지 사진 디렉터리\n",
    "test_dogs_dir = './datasets/small/test/dogs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 고양이 이미지 전체 개수: 101\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 고양이 이미지 전체 개수:', len(os.listdir(train_cats_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 강아지 이미지 전체 개수: 101\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 강아지 이미지 전체 개수:', len(os.listdir(train_dogs_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증용 고양이 이미지 전체 개수: 51\n"
     ]
    }
   ],
   "source": [
    "print('검증용 고양이 이미지 전체 개수:', len(os.listdir(validation_cats_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증용 강아지 이미지 전체 개수: 50\n"
     ]
    }
   ],
   "source": [
    "print('검증용 강아지 이미지 전체 개수:', len(os.listdir(validation_dogs_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트용 고양이 이미지 전체 개수: 50\n"
     ]
    }
   ],
   "source": [
    "print('테스트용 고양이 이미지 전체 개수:', len(os.listdir(test_cats_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트용 강아지 이미지 전체 개수: 50\n"
     ]
    }
   ],
   "source": [
    "print('테스트용 강아지 이미지 전체 개수:', len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202 images belonging to 2 classes.\n",
      "Found 101 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 모든 이미지를 1/255로 스케일을 조정합니다\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # 타깃 디렉터리\n",
    "        train_dir,\n",
    "        # 모든 이미지를 150 × 150 크기로 바꿉니다\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # binary_crossentropy 손실을 사용하기 때문에 이진 레이블이 필요합니다\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=50,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 데이터 크기: (20, 150, 150, 3)\n",
      "배치 레이블 크기: (20,)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('배치 데이터 크기:', data_batch.shape)\n",
    "    print('배치 레이블 크기:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 11 steps, validate for 3 steps\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 6s 526ms/step - loss: 0.7182 - acc: 0.4703 - val_loss: 0.6723 - val_acc: 0.5050\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 5s 467ms/step - loss: 0.6856 - acc: 0.5545 - val_loss: 0.7427 - val_acc: 0.5050\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 5s 464ms/step - loss: 0.6824 - acc: 0.5050 - val_loss: 0.6887 - val_acc: 0.5644\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 5s 483ms/step - loss: 0.6656 - acc: 0.6337 - val_loss: 0.5771 - val_acc: 0.4950\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 5s 486ms/step - loss: 0.6492 - acc: 0.6188 - val_loss: 0.6266 - val_acc: 0.5446\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 5s 486ms/step - loss: 0.6309 - acc: 0.6881 - val_loss: 0.6764 - val_acc: 0.5545\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 5s 494ms/step - loss: 0.5901 - acc: 0.6881 - val_loss: 0.6031 - val_acc: 0.5842\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 6s 503ms/step - loss: 0.5812 - acc: 0.6634 - val_loss: 0.6186 - val_acc: 0.5644\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 6s 513ms/step - loss: 0.5667 - acc: 0.7030 - val_loss: 0.4978 - val_acc: 0.5941\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 6s 508ms/step - loss: 0.5367 - acc: 0.7475 - val_loss: 0.5789 - val_acc: 0.5842\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 6s 507ms/step - loss: 0.5013 - acc: 0.7723 - val_loss: 0.6963 - val_acc: 0.5644\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 6s 509ms/step - loss: 0.4857 - acc: 0.7525 - val_loss: 0.6103 - val_acc: 0.5545\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 6s 520ms/step - loss: 0.4842 - acc: 0.7723 - val_loss: 0.4857 - val_acc: 0.5446\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 6s 515ms/step - loss: 0.4546 - acc: 0.7525 - val_loss: 0.5342 - val_acc: 0.6139\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 5s 498ms/step - loss: 0.3879 - acc: 0.8515 - val_loss: 0.4945 - val_acc: 0.5743\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 5s 496ms/step - loss: 0.4038 - acc: 0.8317 - val_loss: 0.7128 - val_acc: 0.5446\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 5s 497ms/step - loss: 0.3859 - acc: 0.8168 - val_loss: 0.5318 - val_acc: 0.6337\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 6s 504ms/step - loss: 0.3641 - acc: 0.8267 - val_loss: 0.4634 - val_acc: 0.6139\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 5s 493ms/step - loss: 0.3085 - acc: 0.9010 - val_loss: 0.5408 - val_acc: 0.5743\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 5s 492ms/step - loss: 0.3354 - acc: 0.8564 - val_loss: 0.4788 - val_acc: 0.6436\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      #steps_per_epoch=10,\n",
    "      epochs=20,\n",
    "      validation_data=validation_generator,\n",
    "      #validation_steps=50\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "훈련이 끝나면 항상 모델을 저장하는 것이 좋은 습관입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats_and_dogs_small_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model=load_model('cats_and_dogs_small_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=50,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "2/2 [==============================] - 1s 424ms/step - loss: 0.7927 - acc: 0.5900\n",
      "acc: 59.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate(test_generator)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 5 batches). You may need to use the repeat() function when building your dataset.\n",
      "{'cats': 0, 'dogs': 1}\n",
      "[[0.324]\n",
      " [0.385]\n",
      " [0.034]\n",
      " [0.496]\n",
      " [0.305]\n",
      " [0.682]\n",
      " [0.715]\n",
      " [0.323]\n",
      " [0.833]\n",
      " [0.639]\n",
      " [0.478]\n",
      " [0.340]\n",
      " [0.207]\n",
      " [0.534]\n",
      " [0.433]\n",
      " [0.838]\n",
      " [0.363]\n",
      " [0.053]\n",
      " [0.982]\n",
      " [0.416]\n",
      " [0.737]\n",
      " [0.702]\n",
      " [0.151]\n",
      " [0.556]\n",
      " [0.617]\n",
      " [0.623]\n",
      " [0.204]\n",
      " [0.284]\n",
      " [0.959]\n",
      " [0.736]\n",
      " [0.397]\n",
      " [0.058]\n",
      " [0.128]\n",
      " [0.209]\n",
      " [0.571]\n",
      " [0.835]\n",
      " [0.266]\n",
      " [0.780]\n",
      " [0.053]\n",
      " [0.416]\n",
      " [0.225]\n",
      " [0.537]\n",
      " [0.210]\n",
      " [0.253]\n",
      " [0.714]\n",
      " [0.042]\n",
      " [0.414]\n",
      " [0.754]\n",
      " [0.709]\n",
      " [0.786]\n",
      " [0.774]\n",
      " [0.198]\n",
      " [0.811]\n",
      " [0.150]\n",
      " [0.646]\n",
      " [0.090]\n",
      " [0.216]\n",
      " [0.596]\n",
      " [0.795]\n",
      " [0.555]\n",
      " [0.198]\n",
      " [0.031]\n",
      " [0.531]\n",
      " [0.125]\n",
      " [0.484]\n",
      " [0.067]\n",
      " [0.764]\n",
      " [0.481]\n",
      " [0.818]\n",
      " [0.341]\n",
      " [0.504]\n",
      " [0.144]\n",
      " [0.273]\n",
      " [0.750]\n",
      " [0.131]\n",
      " [0.624]\n",
      " [0.363]\n",
      " [0.259]\n",
      " [0.164]\n",
      " [0.919]\n",
      " [0.272]\n",
      " [0.519]\n",
      " [0.425]\n",
      " [0.072]\n",
      " [0.184]\n",
      " [0.886]\n",
      " [0.357]\n",
      " [0.543]\n",
      " [0.326]\n",
      " [0.043]\n",
      " [0.499]\n",
      " [0.703]\n",
      " [0.868]\n",
      " [0.418]\n",
      " [0.318]\n",
      " [0.399]\n",
      " [0.558]\n",
      " [0.582]\n",
      " [0.654]\n",
      " [0.294]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "output = model.predict_generator(test_generator, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(test_generator.class_indices)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
